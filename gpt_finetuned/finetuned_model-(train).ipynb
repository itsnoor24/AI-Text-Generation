{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb04da40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Model, GPT2Tokenizer, AutoTokenizer, GPT2Config, GPT2LMHeadModel, TextDataset,DataCollatorForLanguageModeling, Trainer, TrainingArguments, AutoModelWithLMHead, pipeline\n",
    "from datasets import load_dataset\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import GPT2ForSequenceClassification\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21338b41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>automate td</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>review openapi spec diffs and docs in your prs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a neat summary of the changes you made to your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test api compatibility of changes in your go l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>auto assign reviewer or assignee to pull reque...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   short_description\n",
       "0                                        automate td\n",
       "1     review openapi spec diffs and docs in your prs\n",
       "2  a neat summary of the changes you made to your...\n",
       "3  test api compatibility of changes in your go l...\n",
       "4  auto assign reviewer or assignee to pull reque..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load your dataset\n",
    "df = pd.read_csv(\"gm_actions_preprocessed_more.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef64af",
   "metadata": {},
   "source": [
    "# 1) Load the data (already preprocessed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "210b6a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>review openapi spec diffs and docs in your prs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a neat summary of the changes you made to your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test api compatibility of changes in your go l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>auto assign reviewer or assignee to pull reque...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>var  various automated reviews  is a deadly si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description\n",
       "0     review openapi spec diffs and docs in your prs\n",
       "1  a neat summary of the changes you made to your...\n",
       "2  test api compatibility of changes in your go l...\n",
       "3  auto assign reviewer or assignee to pull reque...\n",
       "4  var  various automated reviews  is a deadly si..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"gm_actions.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fde817c",
   "metadata": {},
   "source": [
    "# 2) Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "135cd3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a 80:20 ratio, split X and Y into [x_train, x_test, y_train, y_test]\n",
    "train,test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba71983",
   "metadata": {},
   "source": [
    "# 3) Convert \"test\" and \"train\" into txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1680a1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(r'train_ds.txt', header=None, index=None, sep=' ', mode='a')\n",
    "test.to_csv(r'test_ds.txt', header=None, index=None, sep=' ', mode='a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936eb32d",
   "metadata": {},
   "source": [
    "# 4) Call GPT tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9e37f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "# set the train and set paths\n",
    "train_path = r\"C:\\Users\\Noor\\Desktop\\eecs 4080\\Noor-Dennis\\Noor\\trained_model\\train_ds.txt\"\n",
    "test_path = r\"C:\\Users\\Noor\\Desktop\\eecs 4080\\Noor-Dennis\\Noor\\trained_model\\test_ds.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb04b498",
   "metadata": {},
   "source": [
    "# 6) Create func that takes the descriptions and puts them in a batch of dictionaries to be used by Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02ba9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(train_path,test_path,tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128)\n",
    "\n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset,test_dataset,data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "224312fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Noor\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\data\\datasets\\language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (7932 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "train_dataset,test_dataset,data_collator = load_dataset(train_path,test_path,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16095a0",
   "metadata": {},
   "source": [
    "# 7) Load and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bcd753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelWithLMHead.from_pretrained(\"gpt2\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-descriptions\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=3, # number of training epochs\n",
    "    per_device_train_batch_size=4, # batch size for training\n",
    "    per_device_eval_batch_size=8,  # batch size for evaluation\n",
    "    eval_steps = 400, # Number of update steps between two evaluations.\n",
    "    save_steps=800, # after # steps model is saved\n",
    "    warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fcd051a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [48/48 03:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=48, training_loss=4.901604016621907, metrics={'train_runtime': 218.6108, 'train_samples_per_second': 0.837, 'train_steps_per_second': 0.22, 'total_flos': 11954110464000.0, 'train_loss': 4.901604016621907, 'epoch': 3.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99581de6",
   "metadata": {},
   "source": [
    "# 8) Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d49de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e767d30c",
   "metadata": {},
   "source": [
    "# 9) Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c91860df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this github action checks if an action can be used to change a value without the action getting deleted (see below). This is similar to the syntax for the actions in git subcommands except you get an array of options that your script can actually modify\n"
     ]
    }
   ],
   "source": [
    "prompt = pipeline('text-generation',model='gpt2-descriptions', tokenizer='gpt2')\n",
    "result = prompt('this github action checks')[0]['generated_text']\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f63b61",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1c3435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4028db71",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac87a343",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a3cfd377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_TensorSliceDataset element_spec=({'input_ids': TensorSpec(shape=(34,), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(34,), dtype=tf.int32, name=None)}, TensorSpec(shape=(), dtype=tf.string, name=None))>\n"
     ]
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47d175",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b6a9f698",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "34818bd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TrainingArguments' object has no attribute 'strategy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[164], line 13\u001b[0m\n\u001b[0;32m      5\u001b[0m model_name \u001b[38;5;241m=\u001b[39m GPT2LMHeadModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# model = TFAutoModelForSequenceClassification.from_pretrained(\"gpt2\")\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# model.compile(optimizer=Adam(3e-5))\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# # model.fit(train_dataset, test_dataset)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# model.fit(train_dataset)\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtraining_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m     14\u001b[0m     model \u001b[38;5;241m=\u001b[39m TFAutoModelForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# training_args= TrainingArguments(\"test-trainer\")\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TrainingArguments' object has no attribute 'strategy'"
     ]
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00db92e2",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "486916f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'I really want my code to work but its not! I want to make it easy to use and maintain.\\n\\nI want to make it easy to use and maintain. I want to make it'}]\n"
     ]
    }
   ],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8eb1e56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc23faa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
